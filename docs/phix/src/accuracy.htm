<head>
 <body>
  <toc>
   <these>
    <get>
     <stripped>
      <h1 class="title">Floats Are Not Exact</h1>
      <div id="mainSection">
<!-- Note that there are infinitely many real numbers, but only a finite number of them (18437736874454810627, to be exact) can be represented exactly by the JavaScript floating-point format. This means that when you're working with real numbers in JavaScript, the representation of the number will often be an approximation of the actual number. The approximation is usually good enough, however, and this is rarely a practical problem. -->
        While all integer values (up to a certain limit, around 10^<sup><small>15</small></sup> on 32-bit 
        and 10^<sup><small>19</small></sup> on 64-bit) are always exact, the same cannot be said for 
        floating point numbers.
        <br>
        <br>
        As mentioned in Number Bases, computers hold numbers in binary, or base 2. And just as our familiar
        decimal system <b>cannot</b> hold <small><sup>1</sup>/<sub>3</sub></small> (one third) exactly, 
        neither can base 2, which also <b>cannot</b> hold <small><sup>1</sup>/<sub>5</sub></small> (one fifth) 
        exactly. It may only be out by the tiniest of amounts, less than, say, the width of an atom (pun
        intended), but it simply <b>cannot</b> be exact. The principle of "close enough" applies.
        <br>
        <br>
        0.1 in decimal is held in binary as 0.0001100110011001100110011001100110011001100110011... i.e.
        <small><sup>0</sup>/<sub>2</sub></small>+<small><sup>0</sup>/<sub>4</sub></small>+
        <small><sup>0</sup>/<sub>8</sub></small>+<small><sup>1</sup>/<sub>16</sub></small>+
        <small><sup>1</sup>/<sub>32</sub></small>+<small><sup>0</sup>/<sub>64</sub></small>+
        <small><sup>0</sup>/<sub>128</sub></small>+<small><sup>1</sup>/<sub>256</sub></small>+
        <small><sup>1</sup>/<sub>512</sub></small>+<small><sup>0</sup>/<sub>1024</sub></small>, etc.
        It gets pretty close, but would never manage to be exact, no matter how many digits you used.
        In fact the only fractions that can be held exactly are a half, quarter, eighth, etc, and any
        value that can be composed as a sum of such fractions.
        <br>
        <br>
        A related but different concept is precision: starting with a value of 1e300, you can try to add
        1 (or for that matter 1e250) to it as many times as you like; it will never make the slightest
        dent, not even if you leave it running for millenia. (Just something you should know.) Obviously
        if you multiply the 1 (or the 1e250) by something before the addition, that&rsquo;s different.
        The actual precision available is about 15 decimal digits on 32 bit and about 19 decimal digits 
        on 64 bit, and accordingly if the ratio between two numbers is too extreme, we find ourselves in
        one of those too small to make a dent situations. If we were only keeping numbers to two decimal
        places, then the most accurate answer for 3.00 plus 0.001 is still 3.00, and something similar 
        happens when we are limited to 15 or 19 significant decimal digits. You get a very different
        answer from ((15+(1e-30))-15) [ie 0] to ((15-15)+(1e-30)) [ie 1e-30], and likewise 1e300+1-1e300
        yeilds 0 whereas 1e300-1e300+1 yields 1.
        <br>
        <br>
        I also rather like the following analogy. You can use atoms to store integer values up to 
        9,007,199,254,740,992, but like a bookshelf without any end stops, once full, if you need an extra 
        bit on the left, then one must fall off the right. In fact, between 9,007,199,254,740,992 and 
        18,014,398,509,481,984 you can only store even numbers, and between 18,014,398,509,481,984 and 
        36,028,797,018,963,968, you can only store numbers divisible by 4, and so on, until by the time 
        you get to 1e300 the "smallest increment" is around 1e285.
        The numbers just given all correspond to a 32-bit system; calculating the equivalents for 64-bit
        systems is left as an exercise for readers with way too much time on their hands.
        <br>
        <br>
        Of course such approximations occur in our familiar decimal system, and in the real world are more 
        prevalent than not. You and I might say 31mm, an engineer 31.147mm, and a physicist 31.147436892mm,
        before adding something completely incomprehensible about lengths being composed of an infinite series 
        of quantum probability functions being distorted by gravitational waves, or something like that. It
        can be annoying that you need to take extra care when dealing with pennies and cents, but is the price
        we pay for having hardware that can also cope with the kind of numbers needed for astrophysics.
        <br>
        <br>
        These features of the physical hardware are common to all programming languages, at least when using 
        the native machine floating point hardware as opposed to a specialised fraction or decimal library 
        component (eg <a href="bigatom.htm">bigatom</a>), which would of course be considerably slower.
        <br>
        <br>
        In particular, <b><i>comparing floating point numbers for equality is almost always the wrong thing to do</i></b>.
        <br>
        <br>
        Instead of <code>(a=10.0)</code> use <code>((a&gt9.99) and (a&lt10.01))</code>, and instead of 
        <code>(a=b)</code> use <code>(abs(a-b)&lt;1e-6)</code>, or similar. 
        Alternatively it would not be unreasonable to design, for instance, an accounting system that 
        internally works in whole pennies/cents, and multiplies by 0.01 (or whatever) just before display.
        <br>
        <br>
        It is for these reasons that Phix does not permit floating point for loops; they simply do not 
        work as expected, besides it is trivial to use an integer control loop variable and a manually
        maintained floating point value to achieve the desired results, without occasionally iterating
        one more or one less than intended.
        <br>
        <br>
        When using a 32-bit compiler to create a 64-bit executable, be aware that the integer range is
        redefined as +/-#FFFF_FFFF rather than -#4000_0000_0000_0000 to #3FFF_FFFF_FFFF_FFFF. See ptok.e/
        setFLOAT() for all the nitty-gritty details. It is also true that the value of PI, and possibly
        some other constants, will be slightly out, by about one trillionth of one percent.
        <br>
        <br>
        See also: 
          <a id="ext437" style="color:#9B5565" 
            href="javascript:ExternalLink('ext437','http://en.wikipedia.org/wiki/Floating_point');">wikipedia
          </a>&nbsp;or 
          <a id="ext477" style="color:#9B5565" 
            href="javascript:ExternalLink('ext477','https://docs.python.org/2/tutorial/floatingpoint.html');">python docs
          </a>
         &nbsp;if for whatever reason you think I might just be making all this stuff up.<img src="Images/ksk-smile.png" />
        <br>
        <br>
      </div>
     </stripped>
    </get>
   </these>
  </toc>
 </body>
</head>
