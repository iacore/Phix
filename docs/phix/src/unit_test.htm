<head>
 <body>
  <toc>
   <these>
    <get>
     <stripped>
      <h1 class="title">unit_test</h1>
      <div id="mainSection">
        The file builtins/unit_test.e (an autoinclude) implements a simple unit testing framework for Phix.
        <br>
        <br>
        Unit testing should be a vital weapon in any half-decent programmer&rsquo;s arsenal, and can be key to a
        <a href="glossary.htm#failfast">fail fast</a> approach.<br>
        It should be just as easy to write a (permanent) unit test as it is to perform that test (once) manually.
        <br>
        <br>
        The theory is simply that if all the components of a system are working correctly, then there is a much
        higher probability that a system using those components can be made to work correctly. I might also add
        that debugging a component in isolation is much easier than leaving it until everything else is ready.
        <br>
        <br>
        Unit tests not only completely eliminate an otherwise extremely tedious phase of the release cycle, but also 
        grant the confidence to make changes that could instead be just far too frightening to even contemplate. 
        I can tell you with absolute certainty and utter seriousness that the phix compiler simply could not have 
        been written without the help of unit testing, full stop. <br>
        While they do not actually use these routines, a quick scan of any of the sixty-odd tests\tnn***.exw files 
        (which predate this) will reveal plenty of opportunities for using test_equal() and friends. <br>
        If I have to spend five or twenty-five minutes crafting the perfect test, and then never have to worry about 
        it ever again, for me that sounds like an absolute bargain and a long-term timesaver that will repay that
        effort many times over in the months and years to come.
        <br>
        <br>
        These routines are fully supported by <a href="p2js.htm"><span class="pwap2js"><b>pwa/p2js</b></span></a>,
        except as noted below there is no way to write a logfile and no way to pause JavaScript execution, not that 
        it should be particularly difficult to restructure some (console-based) code into "before" and "after" 
        routines, with some (GUI-based) means of kicking off the "after" part, probably however needing some new
        and as yet unwritted "get_test_results" routine to explicitly enable/disable some buttons and hide/show
        some messages. The (un-paused) message displays do however all work just fine, and any program that uses
        these routines with 100% [hidden] success rates probably won&rsquo;t need any modification at all.
       <br>
       <h3>Example:</h3>
       <div id="code-snippet-1" class="codeSnippetContainer" xmlns="">
        <div class="codeSnippetContainerCodeContainer">
         <div class="codeSnippetToolBar">
          <div class="codeSnippetToolBarText">
               <a id="copytext" href="javascript:CopyToClipboard('CodeSnippetContainerCode_18b78q53-jb33-1223-123h-8b2483c91876');">Copy</a>
          </div>
         </div>
         <div id="CodeSnippetContainerCode_18b78q53-jb33-1223-123h-8b2483c91876" class="codeSnippetContainerCode" dir="ltr">
          <div style="color:Black;">
<!--eucode>
test_equal(2+2,4,"2+2 is not 4 !!!!")
test_summary()
</eucode-->
<pre>
<font color="#7060A8">test_equal</font><font color="#0000FF">(</font><font color="#000000">2</font><font color="#0000FF">+</font><font color="#000000">2</font><font color="#0000FF">,</font><font color="#000000">4</font><font color="#0000FF">,</font><font color="#008000">"2+2 is not 4 !!!!"</font><font color="#0000FF">)</font>
<font color="#7060A8">test_summary</font><font color="#0000FF">()</font>
</pre>
          </div>
         </div>
        </div>
       </div>
        <br>
        If all goes well, no output is shown, and the program carries on normally. 
        You can easily force [summary/verbose] output, crash/prompt on fail, etc.
        <br>
        <br>
        Note that I have used many of the same routine names as Euphoria, but the parameters are
        all different [esp their order] and therefore they are not compatibile...<br>
         In particular you have to give every test a name in Euphoria, whereas here
         such things are optional. Also, Euphoria works by putting tests in files
         named "t_*" and running eutest, whereas here they are part of the app, and
         will start failing on live systems (eg) if not properly installed.
<!--
         [If you want unit tests to "go away" in production releases, you just need
          eg "global constant UNIT_TESTS = false" and litter "if UNIT_TESTS then"
          throughout your code, and maybe something along similar lines to the way
          that docs/phix/makephix.exw/readtoc() verifies that pglobals.e matches 
          banner.htm, but in your standard build script (assuming you have one).  ]
-->
<!--
-- === Background
-- Unit testing is the process of assuring that the smallest programming units
-- are actually delivering functionality that complies with their specification.
-- The units in question are usually individual routines rather than whole programs
-- or applications.
--
-- The theory is that if the components of a system are working correctly, then
-- there is a high probability that a system using those components can be made
-- to work correctly.
--
-- In Euphoria terms, this framework provides the tools to make testing and reporting on
-- functions and procedures easy and standardized. It gives us a simple way to
-- write a test case and to report on the findings.
-->

        <br>
        <br>
        <a name=constants></a>
        <h2>constants</h2>
        The following constants are automatically defined (in psym.e/syminit).
        <i>TEST_QUIET</i> is shown twice in italics to indicate it is part of all three sets, 
        but obviously it is only actually defined once. The three sets correspond, in order, 
        to the first three functions documented below them:
        <br>
        <br>
        <style type="text/css">
          dl {margin:0;padding:0;}
          dt {margin:0;padding:0;}
          dd {margin:0;padding:0;}
          dd.pad {padding-left:12em;}
        </style>
        <div id="nopad" class="nopad" align="left">
         <table cellspacing="0" cellpadding="0" border="0" style="padding: 0; border-style: none;">
          <col style="width: 5%"/>
          <tr><td align="right" style="padding: 0; border-style: none;">
            <nobr>TEST_QUIET&nbsp;</nobr>
          </td><td align="left" style="padding: 0; border-style: none;">
            = 0 -- (summary only when fail)
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            TEST_SUMMARY&nbsp;
          </td><td align="left" style="padding: 0; border-style: none;">
            = 1 -- (summary only [/always])
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            <nobr>TEST_SHOW_FAILED&nbsp;</nobr>
          </td><td align="left" style="padding: 0; border-style: none;">
            = 2 -- (summary + failed tests)
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            TEST_SHOW_ALL&nbsp;
          </td><td align="left" style="padding: 0; border-style: none;">
            = 3 -- (summary + all tests)
            <br>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            TEST_ABORT&nbsp;
          </td><td align="left" style="padding: 0; border-style: none;">
            = 1 -- (abort on failure, at summary)
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            <i>TEST_QUIET&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <i>= 0</i> -- (carry on despite failure)
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            TEST_CRASH&nbsp;
          </td><td align="left" style="padding: 0; border-style: none;">
            = -1 -- (crash on failure, immediately)
            <br>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            TEST_PAUSE&nbsp;
          </td><td align="left" style="padding: 0; border-style: none;">
            = 1 -- (always pause)
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            <i>TEST_QUIET&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <i>= 0</i> -- (never pause)
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
            TEST_PAUSE_FAIL&nbsp;
          </td><td align="left" style="padding: 0; border-style: none;">
            = -1 -- (pause on failure)
          </td></tr>
         </table>
        </div>
        <div style="clear:both;height:1px;"> </div>

        <a name=routines></a>
        <h2>routines</h2>
        Apart from test_summary(), these are all optional.
        <br>
        <br>
        <div id="nopad" class="nopad" align="center">
         <table cellspacing="0" cellpadding="0" border="0" style="padding: 0; border-style: none;">
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=set_test_verbosity></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>set_test_verbosity</b>(integer level) -- set output verbosity
            </dt><dd class="pad">
            <br>
            level: one of the first four TEST_XXX constants above, the initial default setting is TEST_QUIET
            <br>
            <br>
            Note that (even) TEST_SHOW_ALL will not show <i>successful</i> tests with no name.<br>
            You can use integer level = <b>get_test_verbosity</b>() to retrieve the current setting.
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=set_test_abort></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>set_test_abort</b>(integer abort_test) -- set test failure behaviour
            </dt><dd class="pad">
            <br>
            abort_test: TEST_ABORT/TEST_QUIET/TEST_CRASH as follows
            <br>
            <br>
            if TEST_ABORT then <a href="abort.htm">abort</a>(1) on failure, after showing the summary,<br>
            if TEST_QUIET then quietly carry on (the default), <br>
            if TEST_CRASH then <a href="crash.htm">crash</a>("unit test failure (name)"), immediately.<br>
            You may, of course, change this at will for critical and not-so-critical tests or test sections/modules.<br>
            <br>
            The default setting of TEST_QUIET makes unit test failures a gentle but persistent reminder.<br>
            Setting TEST_CRASH ensures that the ex.err contains a direct link to the (first) offending test,
            and therefore causes Edita/Edix to jump directly to said source code line (admittedly that may not be 
            so helpful when what you really want to do is undo/fix the last edit just made), but also forces you 
            to fix any new problems immediately, before resuming work on anything else.<br>
            Setting TEST_ABORT can likewise inhibit working on anything else if the test_summary() is invoked
            early on, say as part of the initialisation routines, whereas, of course, if it is invoked
            as part of the shutdown process it may act more as a gentle reminder.<br>
            You can use integer abort_test = <b>get_test_abort</b>() to retrieve the current setting.<br>
<!--            
            non-zero value will force you to fix any new problems immediately, before working on anything else.<br>
            The default of zero allows you to carry on working on other things, but with a persistent reminder,
            whereas a non-zero value will force you to fix any new problems immediately, with -1 ensuring that
            the ex.err contains a direct link to the (first) offending test.
===
            Obviously if you invoke test_summary() early on, say as part of the initialisation routines,
            then a non-zero value  before working on anything else.<br>
            Conversely, invoking test_summary() as late as possible gives a more gentle (but presistent) reminder.<br>
            The -1 setting 
-->
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=set_test_pause></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>set_test_pause</b>(integer pause) -- set pause behaviour (at summary)
            </dt><dd class="pad">
            <br>
            pause: TEST_PAUSE/TEST_QUIET/TEST_PAUSE_FAIL as follows<br>
            <br>
            if TEST_PAUSE always pause, <br>
            if TEST_QUIET never pause, <br>
            if TEST_PAUSE_FAIL pause on failure (the default).<br>
            You can use integer to_wait = <b>get_test_pause</b>() to retrieve the current setting.<br>
            Under <a href="p2js.htm"><span class="pwap2js"><b>pwa/p2js</b></span></a> the module
            always behaves as TEST_QUIET and invoking routine this has no effect whatsoever, since 
            there is no way to pause JavaScript execution for keyboard input (doing so would be at
            odds with the underlying browser&rsquo;s [gui] event loop), not that it should be particularly
            difficult to restructure some console-based code into something more GUI-friendly.
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=set_test_logfile></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>set_test_logfile</b>(string filename) -- set a log file
            </dt><dd class="pad">
            <br>
            filename: the output file<br>
            <br>
            If this routine is not called, all output is to stderr only.<br>
            The file is automatically closed via test_summary().<br>
            You can use integer log_fn = <b>get_test_logfile</b>() to retrieve the current open log file handle, or 0 if none,<br>
            in case there is something else you want to output to it (as '\n'-terminated plaintext lines).<br>
            Under <a href="p2js.htm"><span class="pwap2js"><b>pwa/p2js</b></span></a> any calls to
            this routine are quietly ignored, since a web browser cannot (easily/realisticly) write a log file.
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=set_test_module></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>set_test_module</b>(string name) -- start a test section (optional)
            </dt><dd class="pad">
            <br>
            name: the test section name<br>
            <br>
            The section/module name is simply a hint to the programmer about where to go to 
            fix some problem just introduced/detected, eg after
            <br>
            <br>
<!--eucode>
        set_test_module("logical")
        ...
        set_test_module("relational")
        ...
        set_test_module("regression")
        ...
        test_summary()
</eucode-->
<pre>
<font color="#7060A8">        set_test_module</font><font color="#0000FF">(</font><font color="#008000">"logical"</font><font color="#0000FF">)
        ...</font>
<font color="#7060A8">        set_test_module</font><font color="#0000FF">(</font><font color="#008000">"relational"</font><font color="#0000FF">)
        ...</font>
<font color="#7060A8">        set_test_module</font><font color="#0000FF">(</font><font color="#008000">"regression"</font><font color="#0000FF">)
        ...</font>
<font color="#7060A8">        test_summary</font><font color="#0000FF">()</font>
</pre>
            <br>
            if you get (say)
            <br>
 <pre>          
        relational:
          test12 failed: 2 expected, got 4
         20 tests run, 19 passed, 1 failed, 95% success
 </pre>
            <br>
            then you know to look for the "test12" test in the relational section.
            When required, test_summary(false) is automatically invoked by set_test_module(), and 
            you must invoke test_summary() at the end, or risk getting no output whatsoever.<br>
            Just for my sanity, <b>set_test_section</b>() is an alias of set_test_module() (in
            psym.e) and therefore obviously behaves absolutely identically.<br>
            Obviously you are free to use any appropriate section names, and if
            you never invoke set_test_module() they are all lumped in together.<br>
            Likewise it is perfectly fine if you cannot be bothered to name the individual tests, 
            just potentially a bit more of a hunt should they trigger.
            <br>
            <br>
            Suppose you have set_test_module("pGUI:paranormalise") - not actually using these routines but you can find a nice little unit test set 
            there - I suggest you terminate it with set_test_module("pGUI:paranormalise ends"). Now, if there are no unit tests before the next call
            to set_test_module() [or test_summary()] then the "xxx ends" remains empty and is quietly ignored. Should anything land in such, then it
            is someone else&rsquo;s problem for not invoking set_test_module() before starting their tests.
<!--
            If this routine is not called, all output is lumped together<br>
            &nbsp;(and likewise unique names for every individual test are also optional).<br>
            Providing appropriate section names may make it easier to locate a failing test.<br>
            Should the internal tests_run counter be non-zero, this invokes test_summary(<small><i>false</i></small>).
-->
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=test_equal></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>test_equal</b>(object a, b, string name="", [sequence args={},]
                                           bool_or_string bApprox=<a href="logicops.htm#tf">false</a><small><i>,
                                           bool eq=<a href="logicops.htm#tf">true</a></i></small>)
            </dt><dd class="pad">
            <br>
            test two values for (approximate) equality
            <br>
            <br>
            a, b: the two values which should be equal.<br>
            name: the test name (optional).<br>
            args: (optional) if not sequence-but-not-string params[5..6] := params[4..5], iyswim, otherwise
                             if not {} a name=sprintf(name,args) is performed.<br>
            bApprox: use approximate equality, see below (optional).<br>
            <small><i>eq: for internal use only: <a href="logicops.htm#tf">true</a> means it is test_equal() rather 
            than test_not_equal(), and vice versa.</i></small><br>
<!--
            <small>&nbsp;<i>&nbsp;(Ignore that without a matching shim, and you&rsquo;ll mess up the crash(nFrames) handling.)</i></small><br>
-->
            <br>
            When bApprox is false, everything must match exactly (the default). A value of true is the same as "%g", and other
            <a href="sprintf.htm">sprintf</a>() format strings such as "%5.2f" can be specified, in which case it uses a recursive/nested
            <code>(a==b) or (sprintf(fmt,a)==sprintf(fmt,b))</code> test, in other words the sprintf() are only triggered when actually 
            needed and only apply to pairs of atoms in the same place/depth in (as yet at least) identical shapes/structures.
<!-- (leave it out!)
            <br>
            <br>
            Some discrepancies may occur in the handling of strings when bApprox!=false, specifically {'a','b','c'} becomes unequal to "abc"
            but only when something else mismatches, but passes bApprox, let me know should that cause any grief. In some cases you might
            want to take advantage of that to prove you get strings-for-strings, not dword_sequences treated equal for compatibility sake.
-->
<!-- (erm, I might pull this...)
            While for compatibility reasons "abc" and {'a','b','c'} are usually equivalent, that is deemed inappropriate here and any 
            strings in either of a and b must also be strings in the other, so those <i>won&rsquo;t</i> match.<br>
            Should something fail that you think should pass, or perhaps vice versa, your best bet is probably to write your own close_enough() 
            or approximately_equal() routine and pass the result of that to test_true(), or perhaps test_false(). 
            I will consider incorporating any such code posted (and discussed/debated over) on euforum into the next release. 
            You might also consider using locally defined constants such as TEST_MONEY (0.001), TEST_PERCENT (0.1), TEST_SPRINTFG ("%g"), or 
            TEST_1EM9 (1e-9), etc.
-->
<!--
TEST_MONEY: round(a)=round(b) and round((a-round(a))*100)=round((b-round(b))*100), or as TEST_SPRINTFG but using "%.2f".
TEST_PERCENT: {a,b}=sort(sq_abs({a,b}), abs(1-a/b)<1e6 (never tried anything like that. as a!=b min/max avoids /0. unsure about 6dp tho)
TEST_SPRINTFG: sprintf("%10g")=sprintf("%10g",b)    -- the list is literally endless...
-->
            <br>
            <br>
            Omitting the name is probably only sensible when a and/or b already contain sufficient information to identify the failing test.<br>
            Normally the lowest-level error logging prints a and b using "%v", however when they are both "\nhelpful strings" that begin with
            '\n' (which could in fact also be the not-deliberately-planned consequence of a bApprox applied to two atoms) it will use "%s",
            which will effectively hide the '\n' but may hopefully help make some error messages much easier to read. Conversely there may be
            cases when you need to deliberately crop or artificially prefix leading '\n' to get the more precise form back.
<!--
            <br>
            <br>
            The Euphoria version of this routine uses (name,a,b) parameters, so there is a little compatibility shimmying going on which 
            reorders the parameters when either lengths or equality suggest that is the right thing to do, but only when both a and b are
            strings, and name is <i>not</i> "", and obviously it would have given a compilation error or run-time crash anyway were name 
            not a string, plus of course I made name third so that it can be optional. Note this means that test_equal("one","two","two") 
            will in fact pass, however test_equal("one","two","one") will still fail, in others words b==name is potentially a bit dodgy.
-->
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=test_not_equal></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>test_not_equal</b>(object a, b, string name="", [sequence args={},]
                                               bool_or_string bApprox=<a href="logicops.htm#tf">false</a><small><i>) -- test two values for inequality
            </dt><dd class="pad">
            <br>
            a, b: the two values which should <i>not</i> be (approximately) equal.<br>
            <br>
            Note this simply invokes test_equal(a,b,name,args,bApprox,false).
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=test_true></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>test_true</b>(bool success, string name="", sequence args={}) -- test something is true
            </dt><dd class="pad">
            <br>
            success: a value which should be <a href="logicops.htm#tf">true</a><br>
            name: the test name (optional but recommended)<br>
            args: if not {}, name=sprintf(name,args) is performed<br>
            <br>
            Unless set_test_abort(TEST_CRASH) is in force, omitting the name may make it harder to identify the failing test, 
            although when there are only a few tests [in a section/module], that is unlikely to be a significant issue.<br>
            Invokes exactly the same private internal routine as the second half of test_equal() and the following three 
            public routines (but all with differing args).
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=test_false></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>test_false</b>(bool success, string name="", sequence args={}) -- test something is false
            </dt><dd class="pad">
            <br>
            success: a value which should be false<br>
            <br>
            Equivalent to test_true(not success,name,args)
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=test_pass></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>test_pass</b>(string name="", sequence args={}) -- a test has succeeded
            </dt><dd class="pad">
            <br>
            Equivalent to test_true(true,name,args)
            <br>
            <br>
            Typically used when some condition does not easily fit on one line, the main/only point of invoking this directly 
            would be to see the number of passed tests (briefly) pop up or lie waiting as proof in some log file.
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=test_fail></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>test_fail</b>(string name="", sequence args={}) -- a test has failed
            </dt><dd class="pad">
            <br>
            Equivalent to test_true(false,name,args)
            <br>
            <br>
            Typically used when some condition does not easily fit on one line.
            </dd></dl>
            <br>
          </td></tr>
          <tr><td align="right" style="padding: 0; border-style: none;">
           <a name=test_summary></a>
            <i>procedure&nbsp;</i>
          </td><td align="left" style="padding: 0; border-style: none;">
            <dl><dt>
            <b>test_summary</b>(<small><i>bool close_log=<a href="logicops.htm#tf">true</a></i></small>) -- show test summary (if appropriate)
            </dt><dd class="pad">
            <br>
            <small><i>close_log: do not provide/for internal use: allows set_test_module() to keep any log file open.</i></small><br>
            <br>
            Optionally prints eg "20 tests run, 19 passed, 1 failed, 95% success\n", along with an optional
            "Press any key to continue..." pause, closes any log file, and/or aborts.<br>
            Should you forget to invoke this routine, and TEST_QUIET or TEST_SUMMARY is in force, it is quite possible that all 
            failures may go completely unnoticed, and even with a higher setting they may flash up on the screen but disappear 
            too quickly to be read, especially that is after set_test_pause(TEST_QUIET).<br>
            Use set_test_module() for all but the last in preference to invoking this several times, except just prior to abort(), crash(), etc.
            </dd></dl>
            <br>
          </td></tr>
         </table>
        </div>
        <div style="clear:both;height:1px;"> </div>
        <br>
        <h2>Regarding BDD, TDD, etc.</h2>

        Tests are brilliant, they really are, and inadequate tests are, well, just inadequate. TDD/BDD both risk approaching the problem from 
        100% the wrong angle, not that I have any objection to writing maybe 10% or even 20% of tests up-front. <br>
        The very best tests are those that promise (as best anything can) some customer will not re-experience the (apparently) exact same 
        problem this time next week/month - <i>every</i> (non-trivial) maintenance task should result in a new unit test, whether that uses 
        unit_test.e or is simply a <a href="crash.htm">crash</a>() (/assert) statement. <small>[Of course unit_test.e is intended to alert
        you about a problem without unnecessarily hindering development, whereas a crash() can often stop it dead in its tracks.]</small><br>
        Nearly as good are tests that actively assist in the development process by preventing the re-emergence of bugs that just bit you. <br>
        Utterly useless tests are the ones that can never trigger, and the big problem with TDD/BDD is they are placed front and centre, and 
        <i>worse</i> should they in any way actively deter writing tests that utilise knowledge learnt during implementation. <br>
        Where TDD/BDD shines is when you know up-front that nothing will be learnt and there will be absolutely no innovation, which is the 
        very definition of soul-destroying. The same applies to some forms of <a href="OOP.htm">OOP</a> that insist on the creation of
        entire classes so banal and trivial that TDD/BDD suffices. One good thing about TDD is that it deters the use of toolchains with
        primitive run-time diagnostics, ie C++, C, Assembler, vs. everything from Java and Python and of course Phix, which at least try to
        be helpful to the developer.
        <br>
        <br>
        <br>
      </div>
     </stripped>
    </get>
   </these>
  </toc>
 </body>
</head>
